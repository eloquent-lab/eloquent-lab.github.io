detail now. So there is a lot of different automatic evaluation metrics. As I said, there were years and still running, years of competition. How do people like, which metric matches better the human assessments. So many metrics were created. The one that still remains the standard in the field is called BLER and it is
Takže tu máme výstup, a legislatory vzpět, že to bude vzpět v dnech dnes. Máme výstupního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradičního tradiční
if a particular sequence of four words is confirmed by the reference, then the system is getting one foreground. So the first system, which is phrase-based translation, Moses open source machine translation system, in unigrams it produced nine good ones. So one, two, three, four, five, six, seven, eight and the full stop is the ninth out of ten, ten words in total. So it gets score of nine
unigrams, it gets the score of 7 out of 9 bigrams, 5 out of 8 trigrams, and 4 out of 7 4 grams. And so this is like checking whether the long sentences and short sequences are confirmed by the reference. And then to aggregate these n-gram scores, you just take the geometric mean of those,
in a second. So there could be some weights in the geometric mean, but the weights are always said uniformly, because for some situations the longer sentences could be potentially more important than the shorter ones, but people don't care much. Yeah, so this is it. And here you see that Moses, which is phrase-based, has produced many long sequences which were in line
rule-based system produced... well, it said the same thing, but it used different words and it didn't get any foreground and any trigram. It only scored a few individual words and just two bigrams. So here you see that... you already see the
based systems because they got, they were getting higher BLAST scores, they were getting the four grams correct. In that year I think PC Translator was already losing but still it was not losing by that much as the BLAST score suggests.