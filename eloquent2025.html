<html>
  <head>
    <link href='https://fonts.googleapis.com/css?family=Playfair+Display:400,700,900,400italic,700italic,900italic|Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="newspaper.css">
    <title>Eloquent CLEF Lab for evaluation of generative language model quality</title>
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/png" href="favicon.png">
  </head>
  <body>
    <div class="head">
      <div class="headerobjectswrapper">
        <div class="weatherforcastbox">Is your LLM really clever? Can it mark its own homework?</div>
        <header>ELOQUENT Lab 2025</header>
      </div>
      <div class="subhead">2nd edition of the lab for evaluation of generative language model quality at CLEF, the Conference and Labs of the Evaluation Forum</div>
    </div>
    <div class="content">
      <div class="columns">



	<!-- ***  TASK LIST  ***  -->
<!--	
	<div class="column">
	  <div class="head">
	    <span class="headline hl3">Task</span>
	    <span class="headline hl1">Dictionary Definition</span>
	  </div>
	  <p>
The Dictionary Definition Task is new for the second edition, and involves having participating systems play a variant of the popular Dictionary parlour game, implemented and marketed as a popular 1980's board game under various names such as Balderdash, Rappakalja, or Kokkelimonke. The idea is for each player to formulate plausible and convincing definitions to uncommmon and unknown words. These definitions are shared to the other players, with a correct definition mixed in with the player-authored ones, and points are awarded to a player's definition if other players are fooled into believing it to be the true one.

This task will be implemented as a system-submission task, where participants are expected to provide a runnable script to be executed by the organisers. The participants are restricted to a shared set of pre-trained models, which will be fine-tuned over the course of the experiment by the organisers, with both helpful and confounding data, and the scoring will be influenced by the robustness of the script, its prompting, and its continued adaptation to incoming data.  

	  </p>
	  	    <img class="media" src="ordbok.png" alt="an image of a page from a dictionary">
	</div>
	-->
	<!-- ============= -->
	<div class="column">
	  <div class="head">
	    <span class="headline hl3">Task</span>
	    <span class="headline hl1">Voight-Kampff</span>
	    <p>
	      <span class="headline hl4">Can your LLM fool a classifier to believe it is human?</span>
	    </p>
	  </div>
	  <p>
	    This task explores whether automatically-generated text can be distinguished from human-authored text, and is organised in collaboration with the PAN lab at CLEF.
	  </p>
	  <p>
	      <img class="media" src="terminal.png" alt="part human, part machine">
	  </p>
	</div>
	<!-- ============= -->
        <div class="column">
	  <div class="head">
	    <span class="headline hl3">Task</span>
	    <span class="headline hl1">Robustness and Consistency</span>
	  </div>
	  <p>
	    <span class="headline hl4">
	      Will it respond with the same content to all of us?
	    </span>
	  </p>
	  <p>
	    This task ran in 2024 and tests the capability of a model to handle input variation -- e.g.  dialectal, sociolectal, and cross-cultural --  as represented by human-generated equivalent but non-identical varieties of input prompts.
	  </p>
	  <p>
	    <a href="task-robustness-and-consistency/">More information about the task</a>.
	  </p>
	  <p>
	    <img class="media" src="janus.png" alt="janus, a two-faced deity, depicted on a roman coin">
	  </p>
	</div>
	<!-- ============= -->
	<div class="column">
	  <div class="head">
	    <span class="headline hl3">Task</span>
	    <span class="headline hl1">Preference Prediction</span>
	  </div>
	  <p>
	    The Preference Prediction Task is a new task for the second edition and will explore the capabality of systems to predict human preferences for different outputs from generative language models. 
	  </p>
	  <p>
	    We will provide the participants with a novel dataset of human-based preferences and explanations, which will be collected from scratch. This task offers two sub-tasks with participation open to anyone:
<ol><li><b>Preference prediction.</b> Predict human preferences between given LLM responses; performance metric is the accuracy score.</li>
  <li><b>Preference prediction and explanation generation</b> Generate judgements explaining the choices made in sub-task 1; performance metrics include standard natural language generation evaluation metrics.
  </li>
  </ol>

	  </p>
	  <p>
	    <img class="media" src="judge.jpg" alt="John Glynne, Lord Chief Justice">
	  </p>
	  <p>
	    <a href="task-preference-prediction/">More information about the task</a>.
	  </p>
	</div>
	<!-- ============= -->
	<div class="column">
	  <div class="head">
	    <span class="headline hl3">Task</span>
	    <span class="headline hl1">Sensemaking</span>
	  </div>
	  <p>
	    <span class="headline hl4">
	      Can your language model prep, sit, or rate an exam for you?
	    </span>
</p>
	  <p>
In an evolved verion of the first year's Topical Quiz Task, the Sensemaking task will require participating systems to produce a quiz, not for a topic, but for a given syllabus set of texts, potentially noisy or erroneous and to answer to quiz questions posed by other participating systems. A correct answer is one that is aligned with the syllabus without relying on other knowledge. 
		  
	  </p>
	  <p>
	  <img class="media" src="pexels-shvets-production-7516544.jpg" alt="study session">
	  </p>
	  <p>
	    <a href="task-sensemaking/">More information about the task</a>.
	  </p>
	</div>

	<div class="column">
	  <div class="head"><span class="headline hl1">ELOQUENT goals</span></div>
<p>
	  The ELOQUENT evaluation lab experiments with new evaluation methods for generative language models in order to meet some of the challenges in the path from laboratory to application. The intention of the lab is to explore the following important characteristics of generative language model quality:
	  <ol>
<li><b>Trustworthiness</b>: a many-faceted notion which involves topical relevance and truthfulness, discourse competence, reasoning in language, controllability, and robustness across varied input.
<li><b>Multi-linguality and cultural fit</b>: the suitability of a language model for some cultural and linguistic area.
<li><b>Self-assessment</b>: the reliability of a language model to assess the quality of itself or some other language model, using as little human effort as possible.     
<li><b>Limits of language models</b>: the delimitation of world knowledge and generative capacity.
</ol>
</p>
	</div>


	
	<!-- *** EDUCATORS *** -->
	
	<div class="column">
	  <div class="head"><span class="headline hl1">Student projects</span></div>
	  <p>
	    Do you teach a class related to generative language models? Do you supervise students interested in generative language models? Are you a student searching for a project?
	  </p>
	  	    <img class="media" src="astola-img0044.jpeg" alt="a teacher">
	  <p>
	    The ELOQUENT tasks are suitable for use as a class assignment or as a diploma project. Get in touch with us for suggestions of extensions and other ideas!
	  </p>
	</div>
	
	<!-- ***  ABOUT THE WORKSHOP  ***  -->
	

	<div class="column">
          <div class="head"><span class="headline hl5">2025 Workshop in Madrid</span></div>
	  <p>
	    The second ELOQUENT Workshop will be held at the <a href="http://clef2025.clef-initiative.eu/">CLEF conference in Madrid</a>, September 9-12 2024. 
	  </p>
	  <img class="media" src="madrid.jpg" alt="a picture of a building in madrid">
	  <p>
	    The workshop program will hold overview presentations, an invited keynote, and some selected participant presentations.
	  </p>
        </div>

	<!-- ***  HOW TO PARTICIPATE  ***  -->


	<div class="column">
          <div class="head"><span class="headline hl3">Sign up for the tasks!</span></div>
	  <p>
	    Participating in a task can be done as a simple one-off experiment.
	  </p><p>
	    We welcome experimental reports, which will be published in the working notes of the workshop, but there is no requirement to submit anything. If experiments involve hypothesis testing and exploration of more lasting value, they can be revised and published elsewhere in more archival channels. Typically, this is done after the workshops where ideas and learnings have been exchanged between participants. 
	  </p>
	  <p>
	    Sign up to join in the discussion! We will announce a conversation channel here during the fall of 2024.
	  </p>
	    
	    Here is how to participate in the discussion about task details:
	    sign up to join the conversation through the <a href="https://clef2025-labs-registration.dei.unipd.it/">CLEF registration form</a>. 
	  </p>
	  <p>
	    <a href="https://clef2024.clef-initiative.eu"><img src = "clef-logo.png" width="75%" alt="CLEF Logo"></a>
	  </p>
	</div>

	

	<!-- ***  TIMELINE  ***  -->

	<div class="column">
          <div class="head"><span class="headline hl3">
	      Timeline
	  </span></div>
	  <p>
	    <ul>
	      <li> Fall 2024: discussion and task formulation</li>
	      <li> January 1 2024: tasks open and public announcement of tasks</li>
	      <li> April 06 – April 10, 2025: <a href="https://www.ecir2025.eu/">ECIR</a> presentation of ELOQUENT </li>
	      <li> May 2025: submission deadline of experimental runs from participants</li>
	      <li> June 2025: participant report submission deadline </li>
	      <li> July 2025: camera ready report submission deadline </li>
	      <li> 9-12 September 2025: workshop at <a href="http://clef2025.clef-initiative.eu/">CLEF in Madrid</a></li>
	    </ul>
	  </p>
	</div>
	<!-- ***  HISTORY  ***  -->
	<div class="column">	  
          <div class="head"><span class="headline hl1">
	      Previous Editions
	  </span></div>
	  <p>
	    The <a href="eloquent2024.html">first edition of ELOQUENT</a> ran in 2024 and involved four tasks. Two of them continue into this second edition: Voight Kampff and Robustness and Consistency. 
	  </p>
	  <p>
            <div class="head"><span class="subhead">HalluciGen Task</span></div>
	  </p>
	  <p>
	    The task on untruthfulness detection ran in <a href="eloquent2024.html">2024</a> and will move elsewhere for 2025. Return here later to find out more!
	  </p>
	  <p>
	    <img class="media" src="born.jpg" alt="a graffiti from Born with a grinning psychedelic face">
	  </p>
	  <p>
          <div class="head"><span class="subhead">
	      Topical Quiz Task
	    </span></div>
	  </p>
	  <p>
	    The task on probing the topical competence of generative language models ran in <a href="eloquent2024.html">2024</a> and has been developed in to the Sensemaking task for the 2025 edition.
	  </p>
	  <p>
	    <img class="media" src="lecturer.jpeg" alt="a lecturer holding forth about something complex">
	  </p>
        </div>
	<!-- *** Mu-SHROOM *** -->
	<!-- *** Remove or reduce after January *** -->
	<div class="column">
          <div class="head"><span class="headline hl3">Mu-SHROOM</span></div>
          <div class="head"><span class="headline hl4">Related Task</span></div>


<p>
Mu-SHROOM is a non-English-centric SemEval-2025 shared task to advance the SOTA in hallucination detection for content generated with LLMs. Mu-SHROOM has annotated hallucinated content in 10 different languages from top -tier LLMs: Arabic (Modern standard), Chinese (Mandarin), English, Finnish, French, German, Hindi, Italian, Spanish, and Swedish. You can participate in as many languages as you’d like by accurately identifying spans of hallucinated content.
</p>
<p>
<b>Key Dates:</b> Dev set already available; test set released by Jan 10, 2025; evaluation phase ends Jan 31 2025. SemEval workshop in Summer 2025 (co-located with an upcoming *ACL conference). 
</p>


	</div>
	<!-- ***  COMMITTEE  ***  -->

	<div class="column">
          <div class="head"><span class="headline hl3">Organising committee</span></div>
	  	    <img class="media" src="astola-img0051.jpeg" alt="some people at a work table">
	  <p>
	    <ul>
	      <li> <a href="https://www.silo.ai/">AMD Silo AI</a>: Jussi Karlgren</li>
	      <li> <a href="https://www.ai.se/en">   AI Sweden</a>: 		  Magnus Sahlgren</li>
	      <li> <a href="http://toloka.ai/">Toloka AI</a>: Ekaterina Artemova</li> 
	      <li> <a href="https://ufal.mff.cuni.cz/">Charles University</a>: Ond&rcaron;ej Bojar and Pavel &Scaron;indel&aacute;&rcaron;</li>
	      <li> <a href="https://www.iais.fraunhofer.de/en.html">Fraunhofer IAIS</a>: Marie Engels</li>
	      <li> <a href="https://www.mn.uio.no/ifi/english/research/groups/ltg/">University of Oslo: Vladislav Mikhailov, Erik Velldal, Lilja Øvrelid</li> 
	      <li>Accenture and <a href="https://blogs.helsinki.fi/language-technology/">University of Helsinki</a>: Aarne Talman </li> 
	    </ul>
	    Contact us at eloquent-clef2025-organizers&nbsp;AT&nbsp;googlegroups.com
	  </p>
        </div>
ocument}


	<!-- ***  PUBLICATIONS  ***  -->

	<div class="column">
          <div class="head"><span class="headline hl3">Publications</span></div>
	  <p>
	    <ul>
	      <li>
		Overview of ELOQUENT 2024 is in the <a href="https://clef2024.clef-initiative.eu/publications_lncs/637930_1_En_Online_Combine_p2.pdf">
		  CLEF 2024 publication, volume 2
		</a>
	      </li>
	      <li>
		Task reports and participant papers are in the <a href="https://ceur-ws.org/Vol-3740/">CLEF 2024 Working notes</a>: <ul>
		  <li>
		    Topical Quiz: Karlgren & Talman;
		  </li>
		  <li>
		    Hallucigen report: Dürlich et al;
 		  </li>
		  <li>
		    Hallucigen participant: Siino & Tinnirello;
 		  </li>
		  <li>
		    Hallucigen participant: Bui et al. 
		  </li>
		  <li>
		    Robustness: Sahlgren et al;
 		  </li>
		  <li>
		    Robustness participant: Neralla & Bijl de Vroe;
 		  </li>
		  <li>
		    Robustness participant: Simonsen;
		  </li>
		  <li>
		    Voight-Kampff: Bevendoff et al;
 		  </li>
		</ul>
	      <li>
		A first presentation and announcement of ELOQUENT is in the  <a href="https://dl.acm.org/doi/abs/10.1007/978-3-031-56069-9_63">Proceedings of the European Conference on Information Retrieval (ECIR)</a>
<!--		https://link.springer.com/chapter/10.1007/978-3-031-56069-9_63 -->
	      </li>
	    </ul>
	  </p>
	</div>


	<!-- ***  THANKS  ***  -->

	<div class="column">
          <div class="head"><span class="headline hl3">Thank you</span></div>
	  <p>
	    The ELOQUENT lab is supported by the <a href="https://deployaiproject.eu/">DeployAI</a> project through its activities on evaluation of generative language models.
</p><p>
	   Toloka AI also supports the ELOQUENT lab by collecting datasets for the Preference Prediction Task. 
	  </p>

	  <p>
	    Page layout from <a href="https://codepen.io/silkine/pen/QWBxVX">Codepen</a>.
	  </p>
        </div>

      </div>
  </body>
</html>
  
